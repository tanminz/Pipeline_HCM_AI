#!/usr/bin/env python3
"""
Advanced AI Search Engine for HCMC AI Challenge V
With Vector Quantization, Advanced Indexing, and Optimized Search
"""

import os
import json
import logging
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple
import time
from collections import defaultdict
import pickle
import hashlib

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# AI/ML imports
try:
    import torch
    import torch.nn.functional as F
    from transformers import CLIPProcessor, CLIPModel
    import faiss
    from PIL import Image
    import cv2
    from sklearn.cluster import MiniBatchKMeans
    from sklearn.metrics.pairwise import cosine_similarity
except ImportError as e:
    logger.error(f"Critical AI library missing: {e}")
    raise

class AdvancedAISearchEngine:
    def __init__(self, metadata_file="real_image_metadata.json"):
        self.metadata_file = metadata_file
        self.image_metadata = {}
        self.clip_model = None
        self.clip_processor = None
        self.faiss_index = None
        self.clip_features = None
        self.feature_dim = 512  # CLIP ViT-B/32 dimension
        
        # Advanced indexing
        self.quantizer = None
        self.index_file = "fast_faiss_index.bin"
        self.features_file = "fast_clip_features.npy"
        self.quantizer_file = "quantizer.pkl"
        self.valid_ids_file = "fast_valid_ids.pkl"
        
        # Performance tracking
        self.search_times = []
        self.cache_hits = 0
        self.cache_misses = 0
        
        # Enhanced Vietnamese to English translation dictionary
        self.vietnamese_translations = {
            # Animals with detailed descriptions
            'tr√¢u': 'buffalo', 'b√≤': 'cow', 'ch√≥': 'dog', 'm√®o': 'cat', 'chim': 'bird',
            'g√†': 'chicken', 'v·ªãt': 'duck', 'l·ª£n': 'pig', 'd√™': 'goat', 'c·ª´u': 'sheep',
            'ng·ª±a': 'horse', 'voi': 'elephant', 'h·ªï': 'tiger', 's∆∞ t·ª≠': 'lion',
            'kh·ªâ': 'monkey', 'g·∫•u': 'bear', 'c√°': 'fish', 'r·∫Øn': 'snake',
            'l√¢n': 'unicorn', 'r·ªìng': 'dragon', 'ph∆∞·ª£ng ho√†ng': 'phoenix',
            'con tr√¢u': 'buffalo', 'con b√≤': 'cow', 'con ch√≥': 'dog', 'con m√®o': 'cat',
            'con chim': 'bird', 'con g√†': 'chicken', 'con v·ªãt': 'duck', 'con l·ª£n': 'pig',
            'con d√™': 'goat', 'con c·ª´u': 'sheep', 'con ng·ª±a': 'horse', 'con voi': 'elephant',
            'con h·ªï': 'tiger', 'con s∆∞ t·ª≠': 'lion', 'con kh·ªâ': 'monkey', 'con g·∫•u': 'bear',
            'con c√°': 'fish', 'con r·∫Øn': 'snake', 'con l√¢n': 'unicorn', 'con r·ªìng': 'dragon',
            'con ph∆∞·ª£ng ho√†ng': 'phoenix',
            
            # Vehicles with detailed descriptions
            'xe h∆°i': 'car', 'xe m√°y': 'motorcycle', 'xe ƒë·∫°p': 'bicycle', 'xe t·∫£i': 'truck',
            'xe bu√Ωt': 'bus', 't√†u': 'ship', 'm√°y bay': 'airplane', 't√†u h·ªèa': 'train',
            'thuy·ªÅn': 'boat', 'xe': 'vehicle', 't√†u th·ªßy': 'ship', '√¥ t√¥': 'car',
            'xe con': 'car', 'xe kh√°ch': 'passenger car', 'xe t·∫£i nh·ªè': 'small truck',
            'xe t·∫£i l·ªõn': 'large truck', 'xe ƒëua': 'racing car', 'xe th·ªÉ thao': 'sports car',
            
            # People with detailed descriptions
            'ng∆∞·ªùi': 'person', 'ƒë√†n √¥ng': 'man', 'ph·ª• n·ªØ': 'woman', 'tr·∫ª em': 'child',
            'b√©': 'baby', 'b·∫°n': 'friend', 'gia ƒë√¨nh': 'family', 'nh√≥m': 'group',
            'ng∆∞·ªùi ƒë√†n √¥ng': 'man', 'ng∆∞·ªùi ph·ª• n·ªØ': 'woman', 'ng∆∞·ªùi tr·∫ª': 'young person',
            'ng∆∞·ªùi gi√†': 'old person', 'em b√©': 'baby', 'tr·∫ª con': 'children',
            'ph·ª• n·ªØ ƒë·ªôi n√≥n l√°': 'woman wearing conical hat', 'ng∆∞·ªùi ƒë·ªôi n√≥n': 'person wearing hat',
            'ng∆∞·ªùi m·∫∑c √°o d√†i': 'person wearing ao dai', 'ng∆∞·ªùi m·∫∑c √°o': 'person wearing shirt',
            
            # Clothing and accessories
            'n√≥n l√°': 'conical hat', 'n√≥n': 'hat', '√°o d√†i': 'ao dai', '√°o': 'shirt',
            'qu·∫ßn': 'pants', 'v√°y': 'dress', 'gi√†y': 'shoes', 'd√©p': 'sandals',
            't√∫i x√°ch': 'bag', 'c·∫∑p': 'briefcase', 'm≈©': 'cap', 'khƒÉn': 'scarf',
            
            # Nature and environment
            'c√¢y': 'tree', 'hoa': 'flower', 'c·ªè': 'grass', 'l√°': 'leaf',
            'n√∫i': 'mountain', 'ƒë·ªìi': 'hill', 's√¥ng': 'river', 'h·ªì': 'lake',
            'bi·ªÉn': 'sea', 'ƒë·∫°i d∆∞∆°ng': 'ocean', 'b√£i bi·ªÉn': 'beach', 'r·ª´ng': 'forest',
            'n∆∞·ªõc': 'water', 'ƒë·∫•t': 'soil', 'ƒë√°': 'rock', 'c√°t': 'sand',
            'ƒë·ªìng c·ªè': 'meadow', 'c√¥ng vi√™n': 'park', 'c·∫£ng': 'port',
            'c√¢y c·ªëi': 'trees', 'r·ª´ng c√¢y': 'forest', 'v∆∞·ªùn hoa': 'flower garden',
            'b√£i c·ªè': 'grass field', 'ƒë·ªìng l√∫a': 'rice field', 'ru·ªông': 'rice field',
            
            # Buildings and structures
            'nh√†': 'house', 't√≤a nh√†': 'building', 'c·∫ßu': 'bridge', 'ƒë∆∞·ªùng': 'road',
            'ph·ªë': 'street', 'th√†nh ph·ªë': 'city', 'l√†ng': 'village', 'tr∆∞·ªùng': 'school',
            'b·ªánh vi·ªán': 'hospital', 'ch·ª£': 'market', 'nh√† th·ªù': 'church',
            'nh√† b·∫øp': 'kitchen', 'vƒÉn ph√≤ng': 'office', 'c·ª≠a h√†ng': 'shop',
            'nh√† cao t·∫ßng': 'skyscraper', 'chung c∆∞': 'apartment building',
            'bi·ªát th·ª±': 'villa', 'nh√† g·ªó': 'wooden house', 'nh√† s√†n': 'stilt house',
            
            # Objects and items
            'b√†n': 'table', 'gh·∫ø': 'chair', 'gi∆∞·ªùng': 'bed', 't·ªß': 'cabinet',
            'ƒëi·ªán tho·∫°i': 'phone', 'm√°y t√≠nh': 'computer', 's√°ch': 'book', 'b√∫t': 'pen',
            'gi·∫•y': 'paper', '√°o': 'shirt', 'qu·∫ßn': 'pants', 'gi√†y': 'shoes',
            'n·ªìi': 'pot', 't·ªß l·∫°nh': 'refrigerator', 'm√†n h√¨nh': 'screen',
            'laptop': 'laptop', 'v·ª£t': 'racket', 'b√≥ng': 'ball', 'tivi': 'television',
            'qu·∫°t': 'fan', 'ƒë√®n': 'lamp', 'ƒë·ªìng h·ªì': 'clock', 'g∆∞∆°ng': 'mirror',
            'b√¨nh hoa': 'vase', 'ch·∫≠u': 'pot', 'th√πng': 'box', 'h·ªôp': 'box',
            
            # Colors with detailed descriptions
            'ƒë·ªè': 'red', 'xanh': 'blue', 'xanh l√°': 'green', 'v√†ng': 'yellow',
            'ƒëen': 'black', 'tr·∫Øng': 'white', 'n√¢u': 'brown', 'h·ªìng': 'pink',
            't√≠m': 'purple', 'cam': 'orange', 'x√°m': 'gray', 'xanh d∆∞∆°ng': 'blue',
            'xanh l·ª•c': 'green', 'xanh lam': 'blue', 'ƒë·ªè th·∫´m': 'dark red',
            'xanh ƒë·∫≠m': 'dark blue', 'v√†ng nh·∫°t': 'light yellow', 'tr·∫Øng tinh': 'pure white',
            'ƒëen tuy·ªÅn': 'pure black', 'n√¢u ƒë·∫≠m': 'dark brown', 'h·ªìng nh·∫°t': 'light pink',
            'm√†u ƒë·ªè': 'red color', 'm√†u xanh': 'blue color', 'm√†u v√†ng': 'yellow color',
            'm√†u ƒëen': 'black color', 'm√†u tr·∫Øng': 'white color', 'm√†u n√¢u': 'brown color',
            
            # Actions and activities
            'ch·∫°y': 'running', 'ƒëi b·ªô': 'walking', 'ng·ªìi': 'sitting', 'ƒë·ª©ng': 'standing',
            'ƒÉn': 'eating', 'u·ªëng': 'drinking', 'ng·ªß': 'sleeping', 'l√†m vi·ªác': 'working',
            'ch∆°i': 'playing', 'h·ªçc': 'studying', 'ƒë·ªçc': 'reading', 'vi·∫øt': 'writing',
            'nh·∫£y m√∫a': 'dancing', 'bay': 'flying', 'ƒë·∫≠u': 'perching', 'lƒÉn': 'rolling',
            'n·∫•u': 'cooking', 's·∫°c': 'charging', 'neo ƒë·∫≠u': 'anchored', 'ƒë·∫≠u xe': 'parked',
            'ƒëang ch·∫°y': 'running', 'ƒëang ƒëi': 'walking', 'ƒëang ng·ªìi': 'sitting',
            'ƒëang ƒë·ª©ng': 'standing', 'ƒëang ƒÉn': 'eating', 'ƒëang u·ªëng': 'drinking',
            'ƒëang ng·ªß': 'sleeping', 'ƒëang l√†m vi·ªác': 'working', 'ƒëang ch∆°i': 'playing',
            'ƒëang h·ªçc': 'studying', 'ƒëang ƒë·ªçc': 'reading', 'ƒëang vi·∫øt': 'writing',
            'ƒëang nh·∫£y': 'dancing', 'ƒëang bay': 'flying', 'ƒëang ƒë·∫≠u': 'perching',
            'ƒëang lƒÉn': 'rolling', 'ƒëang n·∫•u': 'cooking', 'ƒëang s·∫°c': 'charging',
            
            # Scenes and environments
            'th√†nh ph·ªë': 'city', 'n√¥ng th√¥n': 'rural', 'thi√™n nhi√™n': 'nature',
            'trong nh√†': 'indoor', 'ngo√†i tr·ªùi': 'outdoor', 'ban ng√†y': 'daytime',
            'ban ƒë√™m': 'nighttime', 'm√πa xu√¢n': 'spring', 'm√πa h√®': 'summer',
            'm√πa thu': 'autumn', 'm√πa ƒë√¥ng': 'winter', 'ƒë∆∞·ªùng ph·ªë': 'street',
            'khu v·ª±c n√¥ng th√¥n': 'rural area', 'khu v·ª±c th√†nh th·ªã': 'urban area',
            'khu d√¢n c∆∞': 'residential area', 'khu c√¥ng nghi·ªáp': 'industrial area',
            'khu th∆∞∆°ng m·∫°i': 'commercial area', 'khu vui ch∆°i': 'recreational area',
            
            # Weather and atmosphere
            'm∆∞a': 'rain', 'n·∫Øng': 'sunny', 's∆∞∆°ng m√π': 'fog', 'tuy·∫øt': 'snow',
            'm∆∞a to': 'heavy rain', 'm∆∞a nh·ªè': 'light rain', 'n·∫Øng g·∫Øt': 'intense sun',
            's∆∞∆°ng m√π d√†y ƒë·∫∑c': 'thick fog', 's∆∞∆°ng m√π nh·∫π': 'light fog',
            'tuy·∫øt r∆°i': 'falling snow', 'tuy·∫øt ph·ªß': 'snow covered',
            'tr·ªùi m∆∞a': 'raining', 'tr·ªùi n·∫Øng': 'sunny weather', 'tr·ªùi √¢m u': 'cloudy',
            'tr·ªùi quang': 'clear sky', 'tr·ªùi t·ªëi': 'dark sky',
            
            # Food and dining
            'c∆°m': 'rice', 'rau': 'vegetables', 'm√≥n ƒÉn': 'food', 'th·ªãt': 'meat',
            'c√°': 'fish', 'g√†': 'chicken', 'b√≤': 'beef', 'l·ª£n': 'pork',
            'canh': 'soup', 'ch√°o': 'porridge', 'b√°nh': 'cake', 'k·∫πo': 'candy',
            'nhi·ªÅu m√≥n ƒÉn': 'many dishes', 'ƒë·∫ßy rau xanh': 'full of green vegetables',
            'c∆°m tr·∫Øng': 'white rice', 'm√≥n ƒÉn ngon': 'delicious food',
            'b√†n ƒÉn': 'dining table', 'nh√† b·∫øp': 'kitchen', 'n·ªìi c∆°m ƒëi·ªán': 'rice cooker',
            
            # Sports and recreation
            's√¢n': 'field', 'ƒë∆∞·ªùng ƒëua': 'race track', 's√¢n b√≥ng': 'soccer field',
            's√¢n tennis': 'tennis court', 's√¢n golf': 'golf course', 'h·ªì b∆°i': 'swimming pool',
            'qu·∫£ b√≥ng ƒë√°': 'soccer ball', 'v·ª£t tennis': 'tennis racket',
            'xe ƒë·∫°p ƒëua': 'racing bicycle', 'm√°y ch·∫°y b·ªô': 'treadmill',
            'ƒëang ch∆°i th·ªÉ thao': 'playing sports', 'ƒëang t·∫≠p th·ªÉ d·ª•c': 'exercising',
            
            # Numbers and mathematics
            'm·ªôt': 'one', 'hai': 'two', 'ba': 'three', 'b·ªën': 'four', 'nƒÉm': 'five',
            's√°u': 'six', 'b·∫£y': 'seven', 't√°m': 'eight', 'ch√≠n': 'nine', 'm∆∞·ªùi': 'ten',
            'to√°n': 'math', 'ph∆∞∆°ng tr√¨nh': 'equation', 'b·∫£ng': 'table',
            'nh√¢n': 'multiply', 'ƒë√°p √°n': 'answer', 'b√†i to√°n': 'math problem',
            'b·∫£ng c·ª≠u ch∆∞∆°ng': 'multiplication table', 'ph√©p t√≠nh': 'calculation',
            's·ªë': 'number', 'con s·ªë': 'number', 'ch·ªØ s·ªë': 'digit',
            
            # Technology and electronics
            'di ƒë·ªông': 'mobile', 'ƒë·ªÉ b√†n': 'desktop', 'pin': 'battery',
            'l√†m vi·ªác': 'work', 's√°ch': 'book', 'm√°y t√≠nh ƒë·ªÉ b√†n': 'desktop computer',
            'ƒëi·ªán tho·∫°i di ƒë·ªông': 'mobile phone', 'b√†n l√†m vi·ªác': 'work desk',
            'm√†n h√¨nh l·ªõn': 'large screen', 'm√†n h√¨nh nh·ªè': 'small screen',
            'ƒëang s·∫°c pin': 'charging battery', 'c√≥ laptop': 'with laptop',
            'm√°y in': 'printer', 'm√°y fax': 'fax machine', 'm√°y photocopy': 'photocopier',
            
            # Common descriptive words
            'l·ªõn': 'big', 'nh·ªè': 'small', 'cao': 'tall', 'th·∫•p': 'short',
            'm·ªõi': 'new', 'c≈©': 'old', 'ƒë·∫πp': 'beautiful', 'x·∫•u': 'ugly',
            'nhanh': 'fast', 'ch·∫≠m': 'slow', 'n√≥ng': 'hot', 'l·∫°nh': 'cold',
            'to': 'big', 'd√†y ƒë·∫∑c': 'thick', 'bao ph·ªß': 'covering',
            'chi·∫øu s√°ng': 'shining', 'ph·ªß k√≠n': 'covering', 'r·ªông': 'wide',
            'h·∫πp': 'narrow', 'd√†i': 'long', 'ng·∫Øn': 'short', 'd√†y': 'thick',
            'm·ªèng': 'thin', 'n·∫∑ng': 'heavy', 'nh·∫π': 'light', 'c·ª©ng': 'hard',
            'm·ªÅm': 'soft', 's·∫°ch': 'clean', 'b·∫©n': 'dirty', 's√°ng': 'bright',
            't·ªëi': 'dark', 'r√µ': 'clear', 'm·ªù': 'blurry', 'ƒë·∫ßy': 'full',
            'v·∫Øng': 'empty', 'nhi·ªÅu': 'many', '√≠t': 'few', 't·∫•t c·∫£': 'all',
            'm·ªôt s·ªë': 'some', 'v√†i': 'several', 'm·ªói': 'each', 'm·ªçi': 'every',
            
            # Complex competition phrases and specific cases
            '2 con tr√¢u': 'two buffalo', '3 con b√≤': 'three cow', '5 tr·∫ª em': 'five children',
            '3 ng∆∞·ªùi ƒë√†n √¥ng': 'three men', '2 ph·ª• n·ªØ': 'two women',
            'con l√¢n v√†ng': 'golden unicorn', 'con r·ªìng ƒë·ªè': 'red dragon',
            'con ph∆∞·ª£ng ho√†ng xanh': 'blue phoenix', 'xe h∆°i ƒë·ªè': 'red car',
            'm√°y bay tr·∫Øng': 'white airplane', 't√†u th·ªßy l·ªõn': 'large ship',
            'hoa ƒë√†o h·ªìng': 'pink peach flower', 'l√° c√¢y v√†ng': 'yellow leaves',
            'tuy·∫øt tr·∫Øng': 'white snow', 'n·∫Øng v√†ng': 'golden sun',
            'b√≥ng v√†ng': 'yellow ball', 'nhi·ªÅu m√≥n ƒÉn': 'many dishes',
            'c∆°m tr·∫Øng': 'white rice', 'm√≥n ƒÉn ngon': 'delicious food',
            't√≤a nh√† cao t·∫ßng': 'skyscraper', 'bi·ªÉn xanh': 'blue sea',
            'ƒë·ªìng l√∫a': 'rice field', 's√¢n c·ªè': 'grass field',
            'n·ªü v√†o': 'blooming in', 'r∆°i m√πa': 'falling in season',
            'ƒëang n·∫•u': 'cooking', 'ch·ª©a ƒë·∫ßy': 'full of', 'ƒëang lƒÉn': 'rolling',
            'ch·∫°y tr√™n': 'running on', 'neo ƒë·∫≠u ·ªü': 'anchored at',
            'ƒë·∫≠u tr∆∞·ªõc': 'parked in front of', 'bay tr√™n': 'flying over',
            'c√≥ ƒë√°p √°n': 'with answer', 'l√† 51': 'is 51',
            'x + y = 25': 'x plus y equals 25', 'nh√¢n 7': 'multiply by 7',
            
            # Special cases for competition queries
            'con l√¢n v√†ng m√°u': 'golden blood unicorn', 'con l√¢n v√†ng': 'golden unicorn',
            'con l√¢n': 'unicorn', 'l√¢n v√†ng': 'golden unicorn', 'l√¢n v√†ng m√°u': 'golden blood unicorn',
            'ph·ª• n·ªØ ƒë·ªôi n√≥n l√°': 'woman wearing conical hat', 'ng∆∞·ªùi ph·ª• n·ªØ ƒë·ªôi n√≥n': 'woman wearing hat',
            'ph·ª• n·ªØ m·∫∑c √°o d√†i': 'woman wearing ao dai', 'ng∆∞·ªùi m·∫∑c √°o d√†i': 'person wearing ao dai',
            'xe h∆°i ƒë·∫≠u': 'parked car', 'xe h∆°i ƒëang ch·∫°y': 'running car',
            'xe h∆°i m√†u ƒë·ªè': 'red car', 'xe h∆°i m√†u xanh': 'blue car',
            'xe h∆°i m√†u tr·∫Øng': 'white car', 'xe h∆°i m√†u ƒëen': 'black car',
            'con ch√≥ ƒëang ch·∫°y': 'running dog', 'con ch√≥ ƒëang ng·ªìi': 'sitting dog',
            'con ch√≥ m√†u n√¢u': 'brown dog', 'con ch√≥ m√†u ƒëen': 'black dog',
            'con ch√≥ m√†u tr·∫Øng': 'white dog', 'con ch√≥ nh·ªè': 'small dog',
            'con ch√≥ l·ªõn': 'big dog', 'con ch√≥ con': 'puppy',
            'm√°y bay ƒëang bay': 'flying airplane', 'm√°y bay tr√™n tr·ªùi': 'airplane in sky',
            'm√°y bay m√†u tr·∫Øng': 'white airplane', 'm√°y bay m√†u xanh': 'blue airplane',
            't√†u th·ªßy ƒëang neo': 'anchored ship', 't√†u th·ªßy tr√™n bi·ªÉn': 'ship on sea',
            't√†u th·ªßy l·ªõn': 'large ship', 't√†u th·ªßy nh·ªè': 'small ship',
            'b√£i bi·ªÉn ƒë·∫πp': 'beautiful beach', 'b√£i bi·ªÉn xanh': 'blue beach',
            'r·ª´ng c√¢y xanh': 'green forest', 'r·ª´ng r·∫≠m': 'dense forest',
            'ƒë·ªìng l√∫a v√†ng': 'golden rice field', 'ƒë·ªìng l√∫a xanh': 'green rice field',
            's√¢n c·ªè xanh': 'green grass field', 's√¢n b√≥ng ƒë√°': 'soccer field',
            'c√¥ng vi√™n ƒë·∫πp': 'beautiful park', 'c√¥ng vi√™n xanh': 'green park',
            'th√†nh ph·ªë hi·ªán ƒë·∫°i': 'modern city', 'th√†nh ph·ªë c·ªï': 'old city',
            'l√†ng qu√™': 'rural village', 'l√†ng ngh·ªÅ': 'craft village',
            'ch·ª£ ƒë√¥ng ng∆∞·ªùi': 'crowded market', 'ch·ª£ truy·ªÅn th·ªëng': 'traditional market',
            'nh√† th·ªù c·ªï': 'old church', 'nh√† th·ªù l·ªõn': 'large church',
            'c·∫ßu d√†i': 'long bridge', 'c·∫ßu ƒë·∫πp': 'beautiful bridge',
            'ƒë∆∞·ªùng ph·ªë ƒë√¥ng ƒë√∫c': 'crowded street', 'ƒë∆∞·ªùng ph·ªë v·∫Øng v·∫ª': 'quiet street',
            't√≤a nh√† cao': 'tall building', 't√≤a nh√† hi·ªán ƒë·∫°i': 'modern building',
            'vƒÉn ph√≤ng l√†m vi·ªác': 'working office', 'vƒÉn ph√≤ng hi·ªán ƒë·∫°i': 'modern office',
            'nh√† b·∫øp s·∫°ch s·∫Ω': 'clean kitchen', 'nh√† b·∫øp hi·ªán ƒë·∫°i': 'modern kitchen',
            'ph√≤ng ng·ªß': 'bedroom', 'ph√≤ng kh√°ch': 'living room',
            'ph√≤ng t·∫Øm': 'bathroom', 'ph√≤ng ƒÉn': 'dining room',
            'ban c√¥ng': 'balcony', 's√¢n th∆∞·ª£ng': 'rooftop',
            'h·ªì b∆°i xanh': 'blue swimming pool', 'h·ªì b∆°i l·ªõn': 'large swimming pool',
            'v∆∞·ªùn hoa ƒë·∫πp': 'beautiful flower garden', 'v∆∞·ªùn c√¢y': 'garden',
            'c√¢y c·ªëi xanh t∆∞∆°i': 'lush green trees', 'c√¢y cao': 'tall tree',
            'hoa ƒë·∫πp': 'beautiful flower', 'hoa h·ªìng': 'rose flower',
            'hoa c√∫c': 'chrysanthemum', 'hoa lan': 'orchid',
            'l√° c√¢y xanh': 'green leaves', 'l√° c√¢y v√†ng': 'yellow leaves',
            'l√° c√¢y r∆°i': 'falling leaves', 'c·ªè xanh': 'green grass',
            'c·ªè d·∫°i': 'wild grass', 'c·ªè m·ªçc': 'growing grass',
            'n√∫i cao': 'high mountain', 'n√∫i xanh': 'green mountain',
            'ƒë·ªìi thoai tho·∫£i': 'gentle hill', 'ƒë·ªìi xanh': 'green hill',
            's√¥ng d√†i': 'long river', 's√¥ng xanh': 'blue river',
            'h·ªì n∆∞·ªõc': 'lake', 'h·ªì xanh': 'blue lake',
            'bi·ªÉn xanh': 'blue sea', 'bi·ªÉn ƒë·∫πp': 'beautiful sea',
            'ƒë·∫°i d∆∞∆°ng m√™nh m√¥ng': 'vast ocean', 'ƒë·∫°i d∆∞∆°ng xanh': 'blue ocean',
            'c·∫£ng bi·ªÉn': 'seaport', 'c·∫£ng s√¥ng': 'river port',
            'b√£i c√°t tr·∫Øng': 'white sand beach', 'b√£i c√°t v√†ng': 'golden sand beach',
            'ƒë√° c·ª©ng': 'hard rock', 'ƒë√° to': 'large rock',
            'c√°t m·ªãn': 'fine sand', 'c√°t v√†ng': 'golden sand',
            'ƒë·∫•t ƒëen': 'black soil', 'ƒë·∫•t m√†u m·ª°': 'fertile soil',
            'n∆∞·ªõc trong': 'clear water', 'n∆∞·ªõc xanh': 'blue water',
            'n∆∞·ªõc m∆∞a': 'rainwater', 'n∆∞·ªõc bi·ªÉn': 'seawater',
            'tr·ªùi xanh': 'blue sky', 'tr·ªùi trong': 'clear sky',
            'm√¢y tr·∫Øng': 'white clouds', 'm√¢y x√°m': 'gray clouds',
            'gi√≥ nh·∫π': 'gentle wind', 'gi√≥ m·∫°nh': 'strong wind',
            '√°nh n·∫Øng': 'sunlight', '√°nh s√°ng': 'light',
            'b√≥ng r√¢m': 'shadow', 'b√≥ng m√°t': 'shade',
            'nhi·ªát ƒë·ªô cao': 'high temperature', 'nhi·ªát ƒë·ªô th·∫•p': 'low temperature',
            'kh√¥ng kh√≠ trong l√†nh': 'fresh air', 'kh√¥ng kh√≠ √¥ nhi·ªÖm': 'polluted air',
            'ti·∫øng ·ªìn': 'noise', 'ti·∫øng ƒë·ªông': 'sound',
            's·ª± y√™n tƒ©nh': 'silence', 's·ª± im l·∫∑ng': 'quietness',
            'm√πi h∆∞∆°ng': 'fragrance', 'm√πi th∆°m': 'pleasant smell',
            'm√πi kh√≥ ch·ªãu': 'unpleasant smell', 'm√πi h√¥i': 'bad smell',
            'c·∫£m gi√°c ·∫•m √°p': 'warm feeling', 'c·∫£m gi√°c m√°t m·∫ª': 'cool feeling',
            'c·∫£m gi√°c d·ªÖ ch·ªãu': 'comfortable feeling', 'c·∫£m gi√°c kh√≥ ch·ªãu': 'uncomfortable feeling'
        }
        
        # Load metadata and initialize
        self.load_metadata()
        self.initialize_models()
        self.load_or_build_index()
    
    def translate_vietnamese_to_english(self, query: str) -> str:
        """Translate Vietnamese query to English for better CLIP understanding"""
        try:
            # Use enhanced translator if available
            from enhanced_vietnamese_translator import translate_vietnamese_query
            return translate_vietnamese_query(query)
        except ImportError:
            # Fallback to basic translation
            if not query:
                return query
                
            original_query = query
            translated_query = query.lower()
            
            # Replace Vietnamese words with English equivalents
            for vietnamese, english in self.vietnamese_translations.items():
                translated_query = translated_query.replace(vietnamese.lower(), english)
            
            # Handle common Vietnamese phrases
            phrase_translations = {
                'con tr√¢u': 'buffalo',
                'con b√≤': 'cow', 
                'con ch√≥': 'dog',
                'con m√®o': 'cat',
                'con chim': 'bird',
                'xe h∆°i': 'car',
                'xe m√°y': 'motorcycle',
                'xe ƒë·∫°p': 'bicycle',
                'xe t·∫£i': 'truck',
                'ng∆∞·ªùi ƒëi': 'person riding',
                'ng∆∞·ªùi ƒëang': 'person',
                'tr√™n ƒë∆∞·ªùng': 'on road',
                'trong thi√™n nhi√™n': 'in nature',
                'c√≥ ng∆∞·ªùi': 'with people',
                'm√†u ƒë·ªè': 'red',
                'm√†u xanh': 'blue',
                'm√†u xanh l√°': 'green',
                'm√†u v√†ng': 'yellow',
                'm√†u ƒëen': 'black',
                'm√†u tr·∫Øng': 'white',
                'ƒë∆∞·ªùng ph·ªë': 'street',
                'khu v·ª±c n√¥ng th√¥n': 'rural area',
                'b√£i bi·ªÉn': 'beach',
                'r·ª´ng': 'forest',
                
                # Complex competition phrases
                '2 con tr√¢u': 'two buffalo',
                '3 con b√≤': 'three cow',
                '5 tr·∫ª em': 'five children',
                '3 ng∆∞·ªùi ƒë√†n √¥ng': 'three men',
                '2 ph·ª• n·ªØ': 'two women',
                'con l√¢n v√†ng': 'golden unicorn',
                'con r·ªìng ƒë·ªè': 'red dragon',
                'con ph∆∞·ª£ng ho√†ng xanh': 'blue phoenix',
                'xe h∆°i ƒë·ªè': 'red car',
                'm√°y bay tr·∫Øng': 'white airplane',
                't√†u th·ªßy l·ªõn': 'large ship',
                'm√°y t√≠nh ƒë·ªÉ b√†n': 'desktop computer',
                'ƒëi·ªán tho·∫°i di ƒë·ªông': 'mobile phone',
            'b√†n l√†m vi·ªác': 'work desk',
            'hoa ƒë√†o h·ªìng': 'pink peach flower',
            'l√° c√¢y v√†ng': 'yellow leaves',
            'tuy·∫øt tr·∫Øng': 'white snow',
            'n·∫Øng v√†ng': 'golden sun',
            's∆∞∆°ng m√π d√†y ƒë·∫∑c': 'thick fog',
            'tr·ªùi m∆∞a to': 'heavy rain',
            'n·ªìi c∆°m ƒëi·ªán': 'rice cooker',
            'qu·∫£ b√≥ng ƒë√°': 'soccer ball',
            'v·ª£t tennis': 'tennis racket',
            'xe ƒë·∫°p ƒëua': 'racing bicycle',
            'b√†i to√°n': 'math problem',
            'b·∫£ng c·ª≠u ch∆∞∆°ng': 'multiplication table',
            't√≤a nh√† cao t·∫ßng': 'skyscraper',
            'bi·ªÉn xanh': 'blue sea',
            'ƒë·ªìng l√∫a': 'rice field',
            's√¢n c·ªè': 'grass field',
            'b√≥ng v√†ng': 'yellow ball',
            'm√†n h√¨nh l·ªõn': 'large screen',
            'nhi·ªÅu m√≥n ƒÉn': 'many dishes',
            'ƒë·∫ßy rau xanh': 'full of green vegetables',
            'c∆°m tr·∫Øng': 'white rice',
            'm√≥n ƒÉn ngon': 'delicious food',
            'ƒëang s·∫°c pin': 'charging battery',
            'c√≥ laptop': 'with laptop',
            'n·ªü v√†o': 'blooming in',
            'r∆°i m√πa': 'falling in season',
            'ph·ªß k√≠n': 'completely covering',
            'chi·∫øu s√°ng': 'shining',
            'bao ph·ªß': 'covering',
            'ƒëang n·∫•u': 'cooking',
            'ch·ª©a ƒë·∫ßy': 'full of',
            'ƒëang lƒÉn': 'rolling',
            'ch·∫°y tr√™n': 'running on',
            'neo ƒë·∫≠u ·ªü': 'anchored at',
            'ƒë·∫≠u tr∆∞·ªõc': 'parked in front of',
            'bay tr√™n': 'flying over',
            'c√≥ ƒë√°p √°n': 'with answer',
            'l√† 51': 'is 51',
            'x + y = 25': 'x plus y equals 25',
            'nh√¢n 7': 'multiply by 7'
        }
        
        for phrase, translation in phrase_translations.items():
            translated_query = translated_query.replace(phrase, translation)
        
        # If translation changed the query, log it
        if translated_query != original_query.lower():
            logger.info(f"üåê Translated: '{original_query}' -> '{translated_query}'")
            
        return translated_query
    
    def load_metadata(self):
        """Load and scan all available images"""
        try:
            # Scan all images in static/images directory
            self.scan_all_images()
            logger.info(f"‚úÖ Scanned {len(self.image_metadata)} images from filesystem")
        except Exception as e:
            logger.error(f"‚ùå Error scanning images: {e}")
            self.image_metadata = {}
    
    def scan_all_images(self):
        """Scan all images in the static/images directory"""
        self.image_metadata = {}
        image_id = 0
        
        images_dir = Path("static/images")
        if not images_dir.exists():
            logger.error("static/images directory not found!")
            return
        
        logger.info(f"Scanning images in: {images_dir.absolute()}")
        
        # Scan all subdirectories recursively
        for item in images_dir.rglob("*.jpg"):
            try:
                # Create relative path from static/images
                relative_path = item.relative_to(images_dir)
                
                # Parse the path structure
                path_parts = str(relative_path).split('\\')  # Windows path separator
                
                if len(path_parts) >= 2:
                    video_folder = path_parts[0]  # e.g., Keyframes_L21
                    
                    if len(path_parts) >= 3:
                        video_name = path_parts[-2]  # e.g., L21_V001
                        frame_name = path_parts[-1]  # e.g., 044.jpg
                    else:
                        video_name = path_parts[0]
                        frame_name = path_parts[1]
                    
                    # Create image ID string
                    image_id_str = f"{video_name}/{frame_name}"
                    
                    self.image_metadata[image_id_str] = {
                        'id': image_id,
                        'web_path': str(item),
                        'filename': image_id_str,
                        'video_folder': video_folder,
                        'video_name': video_name,
                        'frame_name': frame_name,
                        'size': item.stat().st_size,
                        'is_real_data': True
                    }
                    
                    image_id += 1
                    
                    if image_id % 1000 == 0:
                        logger.info(f"Scanned {image_id} images...")
                        
            except Exception as e:
                logger.error(f"Error processing {item}: {e}")
                continue
        
        logger.info(f"Total images scanned: {len(self.image_metadata)}")
        
        # Show some examples
        if self.image_metadata:
            sample_keys = list(self.image_metadata.keys())[:5]
            logger.info(f"Sample images: {sample_keys}")
    
    def initialize_models(self):
        """Initialize CLIP model with optimization"""
        try:
            logger.info("üöÄ Loading CLIP model...")
            self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
            self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            
            # Set to evaluation mode
            self.clip_model.eval()
            
            # Move to GPU if available
            if torch.cuda.is_available():
                self.clip_model = self.clip_model.cuda()
                logger.info("‚úÖ CLIP model loaded on GPU")
            else:
                logger.info("‚úÖ CLIP model loaded on CPU")
                
        except Exception as e:
            logger.error(f"‚ùå Error loading CLIP model: {e}")
            raise
    
    def extract_clip_features_batch(self, image_paths: List[str], batch_size: int = 32) -> np.ndarray:
        """Extract CLIP features in batches for efficiency"""
        features_list = []
        
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i + batch_size]
            batch_images = []
            valid_indices = []
            
            # Load batch of images
            for j, path in enumerate(batch_paths):
                try:
                    image = Image.open(path).convert('RGB')
                    batch_images.append(image)
                    valid_indices.append(j)
                except Exception as e:
                    logger.warning(f"Error loading {path}: {e}")
                    continue
            
            if not batch_images:
                continue
            
            try:
                # Process batch with CLIP
                inputs = self.clip_processor(images=batch_images, return_tensors="pt", padding=True)
                
                # Move to GPU if available
                if torch.cuda.is_available():
                    inputs = {k: v.cuda() for k, v in inputs.items()}
                
                # Extract features
                with torch.no_grad():
                    image_features = self.clip_model.get_image_features(**inputs)
                    batch_features = image_features.cpu().numpy()
                    
                    # Add features for valid images
                    for idx in valid_indices:
                        features_list.append(batch_features[idx])
                        
            except Exception as e:
                logger.error(f"Error processing batch {i}: {e}")
                # Add random features for failed batch
                for _ in range(len(batch_paths)):
                    features_list.append(np.random.rand(self.feature_dim))
        
        return np.array(features_list, dtype=np.float32)
    
    def extract_text_features(self, text: str) -> np.ndarray:
        """Extract text features using CLIP"""
        try:
            # Process text
            inputs = self.clip_processor(text=text, return_tensors="pt", padding=True)
            
            # Move to GPU if available
            if torch.cuda.is_available():
                inputs = {k: v.cuda() for k, v in inputs.items()}
            
            # Extract features
            with torch.no_grad():
                text_features = self.clip_model.get_text_features(**inputs)
                features = text_features.cpu().numpy().flatten()
            
            return features
            
        except Exception as e:
            logger.error(f"Error extracting text features: {e}")
            return np.random.rand(self.feature_dim)
    
    def build_quantizer(self, features: np.ndarray, n_clusters: int = 1000):
        """Build vector quantizer for better indexing"""
        try:
            logger.info(f"üî® Building quantizer with {n_clusters} clusters...")
            self.quantizer = MiniBatchKMeans(n_clusters=n_clusters, batch_size=1000, random_state=42)
            self.quantizer.fit(features)
            
            # Save quantizer
            with open(self.quantizer_file, 'wb') as f:
                pickle.dump(self.quantizer, f)
            
            logger.info("‚úÖ Quantizer built and saved")
            
        except Exception as e:
            logger.error(f"Error building quantizer: {e}")
    
    def load_or_build_index(self):
        """Load existing advanced index or build new one"""
        try:
            # Try to load existing index
            if (os.path.exists(self.index_file) and 
                os.path.exists(self.features_file) and 
                os.path.exists(self.quantizer_file)):
                
                logger.info("üìÇ Loading existing advanced FAISS index...")
                self.faiss_index = faiss.read_index(self.index_file)
                self.clip_features = np.load(self.features_file)
                
                with open(self.quantizer_file, 'rb') as f:
                    self.quantizer = pickle.load(f)
                
                with open(self.valid_ids_file, "rb") as f:
                    self.valid_image_ids = pickle.load(f)
                
                logger.info(f"‚úÖ Loaded advanced FAISS index with {len(self.valid_image_ids)} images")
                return
            
            # Build new advanced index
            logger.info("üî® Building new advanced FAISS index...")
            self.build_advanced_search_index()
            
        except Exception as e:
            logger.error(f"Error loading/building advanced index: {e}")
            self.build_advanced_search_index()
    
    def build_advanced_search_index(self):
        """Build advanced FAISS index with vector quantization"""
        try:
            logger.info("üî® Building advanced FAISS search index...")
            
            # Get all image paths
            image_paths = []
            valid_images = []
            
            total_images = len(self.image_metadata)
            for i, (image_id_str, data) in enumerate(self.image_metadata.items()):
                if i % 1000 == 0:
                    logger.info(f"Preparing {i}/{total_images} images...")
                
                image_path = data['web_path']
                if os.path.exists(image_path):
                    image_paths.append(image_path)
                    valid_images.append(image_id_str)
            
            if not image_paths:
                logger.warning("No valid images found for indexing")
                return
            
            logger.info(f"Extracting features for {len(image_paths)} images...")
            
            # Extract features in batches
            self.clip_features = self.extract_clip_features_batch(image_paths, batch_size=32)
            
            # Normalize features
            faiss.normalize_L2(self.clip_features)
            
            # Build quantizer
            self.build_quantizer(self.clip_features, n_clusters=min(1000, len(self.clip_features) // 10))
            
            # Create advanced FAISS index with quantization
            if self.quantizer is not None:
                # Use IVF index with quantizer
                nlist = min(100, len(self.clip_features) // 100)  # Number of clusters
                self.faiss_index = faiss.IndexIVFFlat(self.quantizer, self.feature_dim, nlist)
                self.faiss_index.train(self.clip_features)
                self.faiss_index.add(self.clip_features)
            else:
                # Fallback to simple index
                self.faiss_index = faiss.IndexFlatIP(self.feature_dim)
                self.faiss_index.add(self.clip_features)
            
            # Store valid image IDs
            self.valid_image_ids = valid_images
            
            # Save index and features
            faiss.write_index(self.faiss_index, self.index_file)
            np.save(self.features_file, self.clip_features)
            
            with open(self.valid_ids_file, "wb") as f:
                pickle.dump(self.valid_image_ids, f)
            
            logger.info(f"‚úÖ Advanced FAISS index built and saved with {len(valid_images)} images")
            
        except Exception as e:
            logger.error(f"Error building advanced search index: {e}")
    
    def search_by_text(self, query: str, k: int = 300) -> List[Dict[str, Any]]:
        """Search images by text query with Vietnamese translation support"""
        start_time = time.time()
        
        # Translate Vietnamese to English if needed
        translated_query = self.translate_vietnamese_to_english(query)
        
        try:
            # Encode text query
            text_inputs = self.clip_processor(text=[translated_query], return_tensors="pt", padding=True, truncation=True)
            
            with torch.no_grad():
                text_features = self.clip_model.get_text_features(**text_inputs)
                text_features = F.normalize(text_features, p=2, dim=1)
            
            # Search in FAISS index
            if self.faiss_index is not None:
                # Convert to numpy for FAISS
                query_vector = text_features.cpu().numpy().astype('float32')
                
                # Search
                similarities, indices = self.faiss_index.search(query_vector, k)
                
                # Format results
                results = []
                for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
                    if idx < len(self.valid_image_ids):
                        image_id = self.valid_image_ids[idx]
                        if str(image_id) in self.image_metadata:
                            metadata = self.image_metadata[str(image_id)]
                            results.append({
                                'id': image_id,
                                'path': metadata['web_path'],
                                'filename': metadata['filename'],
                                'similarity': float(similarity),
                                'rank': i + 1,
                                'translated_query': translated_query if translated_query != query else None
                            })
                
                # Track performance
                search_time = time.time() - start_time
                self.search_times.append(search_time)
                
                logger.info(f"üîç Search completed in {search_time:.3f}s")
                logger.info(f"   Query: '{query}' -> '{translated_query}'")
                logger.info(f"   Results: {len(results)}")
                
                return results
            else:
                logger.error("FAISS index not available")
                return []
                
        except Exception as e:
            logger.error(f"Search error: {e}")
            return []
    
    def advanced_search(self, query: str, filters: Dict = None, k: int = 50) -> List[Dict]:
        """Advanced search with multiple strategies"""
        try:
            # Basic text search
            results = self.search_by_text(query, k * 2)
            
            # Apply filters
            if filters:
                results = self.apply_filters(results, filters)
            
            # Re-rank with advanced criteria
            results = self.advanced_rerank(results, query)
            
            return results[:k]
            
        except Exception as e:
            logger.error(f"Error in advanced search: {e}")
            return self.fallback_search(query, k)
    
    def apply_filters(self, results: List[Dict], filters: Dict) -> List[Dict]:
        """Apply advanced filters"""
        filtered_results = []
        
        for result in results:
            # Video folder filter
            if 'video_folder' in filters:
                video_folder = result.get('video_folder', '')
                if filters['video_folder'] not in video_folder:
                    continue
            
            # Video name filter
            if 'video_name' in filters:
                video_name = result.get('video_name', '')
                if filters['video_name'] not in video_name:
                    continue
            
            # Similarity threshold
            if 'min_similarity' in filters:
                if result['similarity'] < filters['min_similarity']:
                    continue
            
            filtered_results.append(result)
        
        return filtered_results
    
    def advanced_rerank(self, results: List[Dict], query: str) -> List[Dict]:
        """Advanced re-ranking with multiple criteria"""
        try:
            query_lower = query.lower()
            query_words = query_lower.split()
            
            for result in results:
                filename = result['filename'].lower()
                video_name = result.get('video_name', '').lower()
                boost = 0.0
                
                # Boost for exact word matches in filename
                for word in query_words:
                    if word in filename:
                        boost += 0.15
                    
                    # Boost for video name matches
                    if word in video_name:
                        boost += 0.1
                
                # Boost for longer queries (more specific)
                if len(query_words) > 1:
                    boost += 0.05
                
                # Apply boost
                result['similarity'] = min(1.0, result['similarity'] + boost)
            
            # Sort by updated similarity
            results.sort(key=lambda x: x['similarity'], reverse=True)
            
            # Update ranks
            for i, result in enumerate(results):
                result['rank'] = i + 1
            
            return results
            
        except Exception as e:
            logger.error(f"Error in advanced reranking: {e}")
            return results
    
    def fallback_search(self, query: str, k: int) -> List[Dict]:
        """Improved fallback search"""
        try:
            query_lower = query.lower()
            results = []
            
            for image_id_str, data in self.image_metadata.items():
                filename_lower = image_id_str.lower()
                video_name = data.get('video_name', '').lower()
                
                # Check if query words appear in filename or video name
                query_words = query_lower.split()
                filename_matches = sum(1 for word in query_words if word in filename_lower)
                video_matches = sum(1 for word in query_words if word in video_name)
                
                total_matches = filename_matches + video_matches
                
                if total_matches > 0:
                    similarity = total_matches / len(query_words)
                    results.append({
                        'id': data['id'],
                        'path': data['web_path'],
                        'filename': image_id_str,
                        'similarity': similarity,
                        'rank': len(results) + 1,
                        'video_folder': data.get('video_folder', 'Unknown'),
                        'video_name': data.get('video_name', 'Unknown')
                    })
            
            # Sort by similarity and limit results
            results.sort(key=lambda x: x['similarity'], reverse=True)
            return results[:k]
            
        except Exception as e:
            logger.error(f"Error in fallback search: {e}")
            return []
    
    def get_search_statistics(self) -> Dict:
        """Get advanced search engine statistics"""
        avg_search_time = np.mean(self.search_times) if self.search_times else 0
        
        return {
            'total_images': len(self.image_metadata),
            'indexed_images': len(self.valid_image_ids),
            'clip_model_loaded': self.clip_model is not None,
            'faiss_index_built': self.faiss_index is not None,
            'quantizer_built': self.quantizer is not None,
            'feature_dimension': self.feature_dim,
            'average_search_time': avg_search_time,
            'cache_size': len(self.cache),
            'gpu_available': torch.cuda.is_available()
        }
    
    def test_search(self, test_queries: List[str] = None):
        """Test the advanced search engine"""
        if test_queries is None:
            test_queries = [
                "buffalo",
                "person",
                "car",
                "building", 
                "nature",
                "indoor scene",
                "outdoor",
                "people",
                "vehicle",
                "animal",
                "water",
                "sky"
            ]
        
        print("üß™ Testing Advanced AI Search Engine...")
        
        for query in test_queries:
            print(f"\nüîç Testing query: '{query}'")
            results = self.search_by_text(query, k=10)
            
            print(f"Found {len(results)} results:")
            for result in results[:5]:  # Show top 5
                print(f"  - {result['filename']} (similarity: {result['similarity']:.3f})")
        
        # Show statistics
        stats = self.get_search_statistics()
        print(f"\nüìä Advanced Search Engine Statistics:")
        for key, value in stats.items():
            print(f"  {key}: {value}")

def main():
    """Main function to test the advanced AI search engine"""
    print("üöÄ Initializing Advanced AI Search Engine...")
    
    try:
        engine = AdvancedAISearchEngine()
        engine.test_search()
        
    except Exception as e:
        logger.error(f"Failed to initialize Advanced AI Search Engine: {e}")
        print("‚ùå Advanced AI Search Engine initialization failed!")

if __name__ == "__main__":
    main()
