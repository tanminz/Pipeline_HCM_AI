#!/usr/bin/env python3
"""
Script t√≠ch h·ª£p data m·ªõi v√†o h·ªá th·ªëng
"""

import os
import shutil
import json
from pathlib import Path
import logging
from tqdm import tqdm

# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_integration.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class DataIntegrator:
    def __init__(self, source_dir="d:/images", target_dir="extracted_data"):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        self.target_dir.mkdir(exist_ok=True)
        
    def get_directory_size(self, directory):
        """T√≠nh dung l∆∞·ª£ng th∆∞ m·ª•c"""
        total_size = 0
        file_count = 0
        
        for root, dirs, files in os.walk(directory):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    total_size += os.path.getsize(file_path)
                    file_count += 1
                except:
                    pass
        
        return total_size, file_count
    
    def copy_keyframes(self, keyframe_dirs):
        """Copy c√°c th∆∞ m·ª•c keyframes m·ªõi"""
        logging.info("üîÑ B·∫Øt ƒë·∫ßu copy keyframes...")
        
        for keyframe_dir in keyframe_dirs:
            source_path = self.source_dir / keyframe_dir
            if not source_path.exists():
                logging.warning(f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {source_path}")
                continue
            
            # T·∫°o t√™n th∆∞ m·ª•c m·ªõi
            new_name = keyframe_dir.replace("Keyframes_", "Keyframes_")
            target_path = self.target_dir / new_name
            
            if target_path.exists():
                logging.info(f"Th∆∞ m·ª•c ƒë√£ t·ªìn t·∫°i, b·ªè qua: {target_path}")
                continue
            
            logging.info(f"Copy {source_path} -> {target_path}")
            
            try:
                shutil.copytree(source_path, target_path)
                size, count = self.get_directory_size(target_path)
                logging.info(f"‚úÖ Ho√†n th√†nh: {count} files, {size/(1024**3):.2f} GB")
            except Exception as e:
                logging.error(f"‚ùå L·ªói copy {source_path}: {e}")
    
    def copy_metadata(self, metadata_dirs):
        """Copy metadata v√† mapping files"""
        logging.info("üîÑ B·∫Øt ƒë·∫ßu copy metadata...")
        
        # T·∫°o th∆∞ m·ª•c metadata
        metadata_target = self.target_dir / "metadata"
        metadata_target.mkdir(exist_ok=True)
        
        for metadata_dir in metadata_dirs:
            source_path = self.source_dir / metadata_dir
            if not source_path.exists():
                continue
            
            # Copy v√†o th∆∞ m·ª•c metadata v·ªõi t√™n m·ªõi
            if "media-info" in metadata_dir:
                target_name = metadata_dir.replace("media-info", "media-info")
            elif "map-keyframes" in metadata_dir:
                target_name = metadata_dir.replace("map-keyframes", "map-keyframes")
            elif "clip-features" in metadata_dir:
                target_name = metadata_dir.replace("clip-features", "clip-features")
            else:
                target_name = metadata_dir
            
            target_path = metadata_target / target_name
            
            if target_path.exists():
                logging.info(f"Metadata ƒë√£ t·ªìn t·∫°i: {target_path}")
                continue
            
            try:
                shutil.copytree(source_path, target_path)
                size, count = self.get_directory_size(target_path)
                logging.info(f"‚úÖ Metadata: {count} files, {size/(1024**2):.2f} MB")
            except Exception as e:
                logging.error(f"‚ùå L·ªói copy metadata {source_path}: {e}")
    
    def copy_objects(self, objects_dirs):
        """Copy object detection data"""
        logging.info("üîÑ B·∫Øt ƒë·∫ßu copy objects data...")
        
        objects_target = self.target_dir / "objects"
        objects_target.mkdir(exist_ok=True)
        
        for objects_dir in objects_dirs:
            source_path = self.source_dir / objects_dir
            if not source_path.exists():
                continue
            
            target_name = objects_dir.replace("objects", "objects")
            target_path = objects_target / target_name
            
            if target_path.exists():
                logging.info(f"Objects data ƒë√£ t·ªìn t·∫°i: {target_path}")
                continue
            
            try:
                shutil.copytree(source_path, target_path)
                size, count = self.get_directory_size(target_path)
                logging.info(f"‚úÖ Objects: {count} files, {size/(1024**2):.2f} MB")
            except Exception as e:
                logging.error(f"‚ùå L·ªói copy objects {source_path}: {e}")
    
    def update_image_metadata(self):
        """C·∫≠p nh·∫≠t file metadata t·ªïng"""
        logging.info("üîÑ C·∫≠p nh·∫≠t image metadata...")
        
        # T√¨m t·∫•t c·∫£ ·∫£nh trong extracted_data
        image_files = []
        for ext in ['.jpg', '.jpeg', '.png']:
            image_files.extend(self.target_dir.rglob(f"*{ext}"))
            image_files.extend(self.target_dir.rglob(f"*{ext.upper()}"))
        
        # T·∫°o metadata m·ªõi
        metadata = {
            "total_images": len(image_files),
            "directories": [],
            "last_updated": str(Path().cwd())
        }
        
        # Th·ªëng k√™ theo th∆∞ m·ª•c
        dir_stats = {}
        for img_file in image_files:
            dir_name = img_file.parent.name
            if dir_name not in dir_stats:
                dir_stats[dir_name] = {"count": 0, "size": 0}
            dir_stats[dir_name]["count"] += 1
            dir_stats[dir_name]["size"] += img_file.stat().st_size
        
        metadata["directories"] = dir_stats
        
        # L∆∞u metadata
        metadata_file = self.target_dir / "image_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        logging.info(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t metadata: {len(image_files)} ·∫£nh")
    
    def integrate_all(self):
        """T√≠ch h·ª£p to√†n b·ªô data m·ªõi"""
        logging.info("üöÄ B·∫ÆT ƒê·∫¶U T√çCH H·ª¢P DATA M·ªöI")
        logging.info("=" * 50)
        
        # Danh s√°ch c√°c th∆∞ m·ª•c c·∫ßn copy
        keyframe_dirs = [f"Keyframes_K{i:02d}" for i in range(1, 15)]
        metadata_dirs = [
            "media-info-aic25-b1",
            "media-info-aic25-b2", 
            "map-keyframes-aic25-b1",
            "map-keyframes-b2",
            "clip-features-32-aic25-b1",
            "clip-features-32-aic25-b2"
        ]
        objects_dirs = ["objects-aic25-b2"]
        
        # Copy keyframes
        self.copy_keyframes(keyframe_dirs)
        
        # Copy metadata
        self.copy_metadata(metadata_dirs)
        
        # Copy objects
        self.copy_objects(objects_dirs)
        
        # C·∫≠p nh·∫≠t metadata
        self.update_image_metadata()
        
        # Th·ªëng k√™ cu·ªëi
        total_size, total_files = self.get_directory_size(self.target_dir)
        logging.info("=" * 50)
        logging.info(f"üéâ HO√ÄN TH√ÄNH T√çCH H·ª¢P!")
        logging.info(f"üìä T·ªïng files: {total_files:,}")
        logging.info(f"üíæ T·ªïng dung l∆∞·ª£ng: {total_size/(1024**3):.2f} GB")

def main():
    integrator = DataIntegrator()
    integrator.integrate_all()

if __name__ == "__main__":
    main()
